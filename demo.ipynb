{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TopicGPT_Python package\n",
    "\n",
    "`topicgpt_python` consists of five modules in total: \n",
    "- `generate_topic_lvl1` generates high-level and generalizable topics. \n",
    "- `generate_topic_lvl2` generates low-level and specific topics to each high-level topic.\n",
    "- `refine_topics` refines the generated topics by merging similar topics and removing irrelevant topics.\n",
    "- `assign_topics` assigns the generated topics to the input text, along with a quote that supports the assignment.\n",
    "- `correct_topics` corrects the generated topics by reprompting the model so that the topic assignment is grounded in the topic list. \n",
    "\n",
    "![topicgpt_python](assets/img/pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "1. Make a new Python 3.9+ environment using virtualenv or conda. \n",
    "2. Install the required packages: `pip install --upgrade topicgpt_python`.\n",
    "- Our package supports OpenAI API, Google Cloud Vertex AI API, Gemini API, Azure API, and vLLM inference. vLLM requires GPUs to run. \n",
    "- Please refer to https://openai.com/pricing/ for OpenAI API pricing or to https://cloud.google.com/vertex-ai/pricing for Vertex API pricing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Run in shell\n",
    "!pip install --upgrade topicgpt_python\n",
    "\n",
    "# Needed only for the OpenAI API deployment\n",
    "export OPENAI_API_KEY={your_openai_api_key}\n",
    "\n",
    "# Needed only for the Vertex AI deployment\n",
    "export VERTEX_PROJECT={your_vertex_project}   # e.g. my-project\n",
    "export VERTEX_LOCATION={your_vertex_location} # e.g. us-central1\n",
    "\n",
    "# Needed only for Gemini deployment\n",
    "export GEMINI_API_KEY={your_gemini_api_key}\n",
    "\n",
    "# Needed only for the Azure API deployment\n",
    "export AZURE_OPENAI_API_KEY={your_azure_api_key}\n",
    "export AZURE_OPENAI_ENDPOINT={your_azure_endpoint}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "1. First, define the necessary file paths for I/O operations in `config.yml`. \n",
    "2. Then, import the necessary modules and functions from `topicgpt_python`.\n",
    "3. Store your data in `data/input` and modify the `data_sample` path in `config.yml`. \n",
    "\n",
    "- Prepare your `.jsonl` data file in the following format:\n",
    "    ```\n",
    "    {\n",
    "        \"id\": \"IDs (optional)\",\n",
    "        \"text\": \"Documents\",\n",
    "        \"label\": \"Ground-truth labels (optional)\"\n",
    "    }\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-06 09:25:18 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from topicgpt_python import *\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Generation \n",
    "Generate high-level topics using `generate_topic_lvl1`. \n",
    "- Define the api type and model. \n",
    "- Define your seed topics in `prompt/seed_1.md`.\n",
    "- (Optional) Modify few-shot examples in `prompt/generation_1.txt`.\n",
    "- Expect the generated topics in `data/output/{data_name}/generation_1.md` and `data/output/{data_name}/generation_1.jsonl`.\n",
    "- Right now, early stopping is set to 100, meaning that if no new topic has been generated in the last 100 iterations, the generation process will stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic generation...\n",
      "Model: gpt-4o\n",
      "Data file: data/input/sample.jsonl\n",
      "Prompt file: prompt/generation_1.txt\n",
      "Seed file: prompt/seed_1.md\n",
      "Output file: data/output/sample/generation_1.jsonl\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:05<00:23,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 610 ~$0.0030499999999999998\n",
      "Response token usage: 19 ~$0.000285\n",
      "Topics: [1] Environment: Involves the management and conservation of natural resources and ecosystems.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:07<00:09,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 1271 ~$0.0063549999999999995\n",
      "Response token usage: 22 ~$0.00033\n",
      "Topics: [1] Environment: Mentions the use of natural resources and the impact of human activities on ecosystems.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:08<00:04,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 823 ~$0.004115\n",
      "Response token usage: 18 ~$0.00027\n",
      "Topics: [1] Environment: Mentions the protection and management of natural habitats and ecosystems.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:09<00:01,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 632 ~$0.0031599999999999996\n",
      "Response token usage: 19 ~$0.000285\n",
      "Topics: [1] Environment: Involves considerations related to sustainable development and environmental review processes.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 566 ~$0.00283\n",
      "Response token usage: 25 ~$0.000375\n",
      "Topics: [1] Immigration: Involves policies and regulations related to the movement of people across borders and their legal status.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<topicgpt_python.utils.TopicTree at 0x7f9e2a15af90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic_lvl1(\n",
    "    \"openai\",\n",
    "    \"gpt-4o\",\n",
    "    config[\"data_sample\"],\n",
    "    config[\"generation\"][\"prompt\"],\n",
    "    config[\"generation\"][\"seed\"],\n",
    "    config[\"generation\"][\"output\"],\n",
    "    config[\"generation\"][\"topic_output\"],\n",
    "    verbose=config[\"verbose\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Refinement\n",
    "If topics are generated by a weaker model, there sometimes exist irrelevant or redundant topics. This module: \n",
    "- Merges similar topics.\n",
    "- Removes overly specific or redundant topics that occur < 1% of the time (you can skip this by setting `remove` to False in `config.yml`).\n",
    "- Expect the refined topics in `data/output/{data_name}/refinement_1.md` and `data/output/{data_name}/refinement_1.jsonl`. If nothing happens, it means that the topic list is coherent.\n",
    "- If you're unsatisfied with the refined topics, call the function again with the refined topic file and refined topic file from the previous iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic refinement...\n",
      "Model: gpt-4o\n",
      "Input data file: data/output/sample/generation_1.jsonl\n",
      "Prompt file: prompt/refinement.txt\n",
      "Output file: data/output/sample/refinement.md\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n",
      "No topic pairs to be merged.\n",
      "No topics removed.\n",
      "Node('/Topics', count=1, desc='Root topic', lvl=0)\n",
      "├── Node('/Topics/Environment', count=4, desc='Involves the management and conservation of natural resources and ecosystems.', lvl=1)\n",
      "└── Node('/Topics/Immigration', count=1, desc='Involves policies and regulations related to the movement of people across borders and their legal status.', lvl=1)\n"
     ]
    }
   ],
   "source": [
    "# Optional: Refine topics if needed\n",
    "if config[\"refining_topics\"]:\n",
    "    refine_topics(\n",
    "        \"openai\",\n",
    "        \"gpt-4o\",\n",
    "        config[\"refinement\"][\"prompt\"],\n",
    "        config[\"generation\"][\"output\"],\n",
    "        config[\"generation\"][\"topic_output\"],\n",
    "        config[\"refinement\"][\"topic_output\"],\n",
    "        config[\"refinement\"][\"output\"],\n",
    "        verbose=config[\"verbose\"],\n",
    "        remove=config[\"refinement\"][\"remove\"],\n",
    "        mapping_file=config[\"refinement\"][\"mapping_file\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtopic Generation \n",
    "Generate subtopics using `generate_topic_lvl2`.\n",
    "- This function iterates over each high-level topic and generates subtopics based on a few example documents associated with the high-level topic.\n",
    "- Expect the generated topics in `data/output/{data_name}/generation_2.md` and `data/output/{data_name}/generation_2.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic generation (lvl 2)...\n",
      "Model: gpt-4o\n",
      "Data file: data/output/sample/generation_1.jsonl\n",
      "Prompt file: prompt/generation_2.txt\n",
      "Seed file: data/output/sample/generation_1.md\n",
      "Output file: data/output/sample/generation_2.jsonl\n",
      "Topic file: data/output/sample/generation_2.md\n",
      "-------------------\n",
      "Number of remaining documents for prompting: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current topic: [1] Environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:03<00:03,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtopics: [1] Environment\n",
      "   [2] Conservation (Document: 1): Focuses on the preservation and management of natural areas, such as roadless areas within national forests.\n",
      "   [2] Indigenous Rights and Compensation (Document: 2): Pertains to the rights and compensation of indigenous tribes for the use of their land, particularly in relation to hydropower projects.\n",
      "   [2] Marine Habitat Protection (Document: 3): Involves the protection of marine ecosystems, specifically related to the conversion of decommissioned oil and gas platforms into artificial reefs.\n",
      "   [2] Sustainable Transportation Development (Document: 4): Concerns the development of transportation systems that are efficient and environmentally sustainable, particularly around major airports.\n",
      "Conservation (Count: 0): Focuses on the preservation and management of natural areas, such as roadless areas within national forests.\n",
      "Indigenous Rights and Compensation (Count: 0): Pertains to the rights and compensation of indigenous tribes for the use of their land, particularly in relation to hydropower projects.\n",
      "Marine Habitat Protection (Count: 0): Involves the protection of marine ecosystems, specifically related to the conversion of decommissioned oil and gas platforms into artificial reefs.\n",
      "Sustainable Transportation Development (Count: 0): Concerns the development of transportation systems that are efficient and environmentally sustainable, particularly around major airports.\n",
      "--------------------------------------------------\n",
      "Current topic: [1] Immigration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtopics: [1] Immigration\n",
      "    [2] Identification and Licensing (Document: 1): Involves regulations and requirements for issuing driver's licenses or identification documents, particularly concerning citizenship or lawful immigration status verification.\n",
      "Identification and Licensing (Count: 0): Involves regulations and requirements for issuing driver's licenses or identification documents, particularly concerning citizenship or lawful immigration status verification.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Optional: Generate subtopics\n",
    "if config[\"generate_subtopics\"]:\n",
    "    generate_topic_lvl2(\n",
    "        \"openai\",\n",
    "        \"gpt-4o\",\n",
    "        config[\"generation\"][\"topic_output\"],\n",
    "        config[\"generation\"][\"output\"],\n",
    "        config[\"generation_2\"][\"prompt\"],\n",
    "        config[\"generation_2\"][\"output\"],\n",
    "        config[\"generation_2\"][\"topic_output\"],\n",
    "        verbose=config[\"verbose\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Assignment\n",
    "Assign the generated topics to the input text using `assign_topics`. Each assignment is supported by a quote from the input text.\n",
    "- Expect the assigned topics in `data/output/{data_name}/assignment.jsonl`. \n",
    "- The model used here is often a weaker model to save cost, so the topics may not be grounded in the topic list. To correct this, use the `correct_topics` module. If there are still errors/hallucinations, run the `correct_topics` module again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic assignment...\n",
      "Model: gpt-4o-mini\n",
      "Data file: data/input/sample.jsonl\n",
      "Prompt file: prompt/assignment.txt\n",
      "Output file: data/output/sample/assignment.jsonl\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:01<00:05,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 509 ~$0.002545\n",
      "Response token usage: 50 ~$0.00075\n",
      "Response: [1] Environment: The document discusses the management and conservation of roadless areas within the National Forest System, which directly relates to environmental conservation efforts. (\"...directs the Secretary of Agriculture to manage such Areas to maintain their roadless character.\")\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:03<00:05,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 1165 ~$0.005825\n",
      "Response token usage: 79 ~$0.0011849999999999999\n",
      "Response: [1] Environment: The document discusses the management and compensation related to the use of land for hydropower generation, which involves environmental considerations and the impact on natural resources. (Supporting quote: \"the purpose of this Act is to compensate the Spokane Tribe of Indians of the Spokane Reservation, Washington State for the use of its land for hydropower generation by the Grand Coulee Dam.\")\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:07<00:05,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 717 ~$0.0035849999999999996\n",
      "Response token usage: 110 ~$0.00165\n",
      "Response: [1] Environment: The document discusses the assessment and management of offshore oil and gas platforms that have become critical for marine fisheries habitat, which directly relates to the conservation of ecosystems. The focus on protecting coral populations and other protected species, as well as the establishment of a Reef Maintenance Fund, emphasizes the environmental aspect of the legislation. \n",
      "\n",
      "Supporting quote: \"Directs the Secretary of the Interior to assess each offshore oil and gas platform in the Gulf of Mexico that is no longer useful for operations, and has become critical for a marine fisheries habitat...\"\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:10<00:02,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 526 ~$0.00263\n",
      "Response token usage: 99 ~$0.001485\n",
      "Response: [1] Environment: The document discusses the establishment of a grant program aimed at developing aerotropolis transportation systems, which includes planning, design, environmental review, and land acquisition activities. This relates to the management and conservation of natural resources and ecosystems as it emphasizes sustainable transportation networks. \n",
      "\n",
      "Supporting quote: \"Directs the Secretary of Transportation to establish an aerotropolis grant program to assist in the development of aerotropolis transportation systems... that provide efficient, sustainable, and intermodal connectivity...\"\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:11<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 460 ~$0.0023\n",
      "Response token usage: 62 ~$0.00093\n",
      "Response: [1] Immigration: The document discusses regulations related to the issuance of driver's licenses and identification documents based on citizenship or lawful immigration status verification requirements. (\"...prohibit a state from issuing a driver's license or identification document to a person unless the state has complied with certain citizenship or lawful immigration status verification requirements.\")\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assignment\n",
    "assign_topics(\n",
    "    \"openai\",\n",
    "    \"gpt-4o-mini\",\n",
    "    config[\"data_sample\"],\n",
    "    config[\"assignment\"][\"prompt\"],\n",
    "    config[\"assignment\"][\"output\"],\n",
    "    config[\"generation\"][\n",
    "        \"topic_output\"\n",
    "    ],  # TODO: change to generation_2 if you have subtopics, or config['refinement']['topic_output'] if you refined topics\n",
    "    verbose=config[\"verbose\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic correction...\n",
      "Model: gpt-4o-mini\n",
      "Data file: data/output/sample/assignment.jsonl\n",
      "Prompt file: prompt/correction.txt\n",
      "Output file: data/output/sample/assignment_corrected.jsonl\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n",
      "Number of errors: 0\n",
      "Number of hallucinated topics: 0\n",
      "All topics are correct.\n"
     ]
    }
   ],
   "source": [
    "# Correction\n",
    "correct_topics(\n",
    "    \"openai\",\n",
    "    \"gpt-4o-mini\",\n",
    "    config[\"assignment\"][\"output\"],\n",
    "    config[\"correction\"][\"prompt\"],\n",
    "    config[\"generation\"][\n",
    "        \"topic_output\"\n",
    "    ],  # TODO: change to generation_2 if you have subtopics, or config['refinement']['topic_output'] if you refined topics\n",
    "    config[\"correction\"][\"output\"],\n",
    "    verbose=config[\"verbose\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
